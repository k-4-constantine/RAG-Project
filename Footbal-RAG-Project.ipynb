{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2df016d2-1f02-491f-9641-b75aec27a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (1.0.1)\n",
      "Name: python-dotenv\n",
      "Version: 1.0.1\n",
      "Summary: Read key-value pairs from a .env file and set them as environment variables\n",
      "Home-page: https://github.com/theskumar/python-dotenv\n",
      "Author: Saurabh Kumar\n",
      "Author-email: me+github@saurabh-kumar.com\n",
      "License: BSD-3-Clause\n",
      "Location: /opt/anaconda3/lib/python3.11/site-packages\n",
      "Requires: \n",
      "Required-by: anaconda-cloud-auth, pydantic-settings, pymilvus\n",
      "---\n",
      "Name: pymilvus\n",
      "Version: 2.5.4\n",
      "Summary: Python Sdk for Milvus\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Milvus Team <milvus-team@zilliz.com>\n",
      "License: \n",
      "Location: /opt/anaconda3/lib/python3.11/site-packages\n",
      "Requires: grpcio, milvus-lite, pandas, protobuf, python-dotenv, setuptools, ujson\n",
      "Required-by: langchain-milvus\n",
      "Found existing installation: backports.tarfile 1.2.0\n",
      "Uninstalling backports.tarfile-1.2.0:\n",
      "  Successfully uninstalled backports.tarfile-1.2.0\n",
      "Collecting backports.tarfile\n",
      "  Using cached backports.tarfile-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Using cached backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\n",
      "Installing collected packages: backports.tarfile\n",
      "Successfully installed backports.tarfile-1.2.0\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.11/site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-core in /opt/anaconda3/lib/python3.11/site-packages (0.3.41)\n",
      "Requirement already satisfied: langchain-azure-ai in /opt/anaconda3/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-azure-ai) (3.11.13)\n",
      "Requirement already satisfied: azure-ai-inference<2.0.0,>=1.0.0b7 in /opt/anaconda3/lib/python3.11/site-packages (from azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (1.0.0b9)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.32.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-azure-ai) (1.32.0)\n",
      "Requirement already satisfied: azure-cosmos<5.0.0,>=4.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-azure-ai) (4.9.0)\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.15.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-azure-ai) (1.20.0)\n",
      "Requirement already satisfied: langchain-openai<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-azure-ai) (0.3.7)\n",
      "Requirement already satisfied: numpy<2.0,>=1.24 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-azure-ai) (1.26.4)\n",
      "Requirement already satisfied: pymongo<5.0.0,>=4.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-azure-ai) (4.11.2)\n",
      "Requirement already satisfied: simsimd<7.0.0,>=6.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-azure-ai) (6.2.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (2.4.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (1.18.3)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /opt/anaconda3/lib/python3.11/site-packages (from azure-ai-inference<2.0.0,>=1.0.0b7->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (0.7.2)\n",
      "Requirement already satisfied: azure-core-tracing-opentelemetry in /opt/anaconda3/lib/python3.11/site-packages (from azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (1.0.0b11)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from azure-core<2.0.0,>=1.32.0->langchain-azure-ai) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (42.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in /opt/anaconda3/lib/python3.11/site-packages (from azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (1.31.1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (1.65.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (0.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/anaconda3/lib/python3.11/site-packages (from pymongo<5.0.0,>=4.5.0->langchain-azure-ai) (2.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (1.16.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (2.4.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from msal-extensions>=1.2.0->azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (2.10.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (1.8.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (2023.10.3)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (1.30.0)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (2.21)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (7.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (1.14.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.11/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (3.17.0)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.11/site-packages (3.3.2)\n",
      "Requirement already satisfied: langchain-huggingface in /opt/anaconda3/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: langchain-milvus in /opt/anaconda3/lib/python3.11/site-packages (0.1.8)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.29.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-huggingface) (0.3.41)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-huggingface) (3.4.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-huggingface) (0.21.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-huggingface) (4.49.0)\n",
      "Requirement already satisfied: pymilvus<3.0.0,>=2.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-milvus) (2.5.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.3.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.6)\n",
      "Requirement already satisfied: setuptools>69 in /opt/anaconda3/lib/python3.11/site-packages (from pymilvus<3.0.0,>=2.5.0->langchain-milvus) (75.8.2)\n",
      "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in /opt/anaconda3/lib/python3.11/site-packages (from pymilvus<3.0.0,>=2.5.0->langchain-milvus) (1.67.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /opt/anaconda3/lib/python3.11/site-packages (from pymilvus<3.0.0,>=2.5.0->langchain-milvus) (3.20.3)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from pymilvus<3.0.0,>=2.5.0->langchain-milvus) (1.0.1)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from pymilvus<3.0.0,>=2.5.0->langchain-milvus) (5.4.0)\n",
      "Requirement already satisfied: milvus-lite>=2.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from pymilvus<3.0.0,>=2.5.0->langchain-milvus) (2.4.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.11.4)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers>=4.39.0->langchain-huggingface) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: rank_bm25 in /opt/anaconda3/lib/python3.11/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from rank_bm25) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "!pip install --upgrade python-dotenv\n",
    "!pip install \"python-dotenv>=1.0.1,<2.0.0\"\n",
    "!pip show python-dotenv pymilvus\n",
    "!pip uninstall backports.tarfile -y\n",
    "!pip install backports.tarfile\n",
    "!pip install langchain langchain-core langchain-azure-ai\n",
    "! pip install datasets langchain-huggingface langchain-milvus\n",
    "# LangChain core and modules\n",
    "from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\n",
    "from langchain_milvus import Milvus\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\n",
    "from langchain_azure_ai.embeddings import AzureAIEmbeddingsModel\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "!pip install rank_bm25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "036d4013-2abc-4fe7-a7fb-2ac1ff5f8e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ENDPOINT = \"http://81.171.3.27:65432/models\"\n",
    "API_KEY = \"g7Ma8ocYuhTBasjL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e457d6eb-976c-47cc-b82d-4d6ac24378f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Chatbot Ready! Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ You:  que est ce\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Refined Query: <think>\n",
      "Okay, let me try to figure out what the user is asking here. The query is \"que est ce\" which is French. Translating that, it should be \"Qu'est-ce que...\" which means \"What is...\" in English. But the user only wrote \"que est ce\" which is a bit broken. Maybe they meant to ask \"Qu'est-ce que c'est?\" which translates to \"What is this?\" or \"What is that?\".\n",
      "\n",
      "Looking at the conversation history, it's empty. So there's no prior context to go off. The user might be starting a new conversation. Since the query is in French, I should consider that they're a French speaker or prefer French responses. But the query is incomplete, so they probably need help forming a proper question. \n",
      "\n",
      "They might be trying to ask \"What is...\" followed by something specific. Maybe they're unsure how to phrase their question correctly in French. For example, \"Qu'est-ce que la philosophie?\" (What is philosophy?) or \"Qu'est-ce que le temps?\" (What is time?). But without more context, it's hard to tell. \n",
      "\n",
      "Alternatively, \"que est ce\" could be a typo. Maybe they intended to write \"Qu'est-ce que...\" but missed some letters or accents. Common mistakes when typing quickly. So I need to account for possible typos and think about what the user is trying to ask. \n",
      "\n",
      "Since the user's query is incomplete, the best approach is to ask for clarification. But the task here is to refine the query for better document retrieval. So I need to think of possible expansions or corrections. \"Que est ce\" is likely \"Qu'est-ce que...\" followed by a subject. So maybe the refined query should be \"Qu'est-ce que [subject]?\" prompting the user to specify the subject they're asking about. \n",
      "\n",
      "Alternatively, if the user just wants a general question structure, the refined query could be \"Qu'est-ce que c'est ?\" to mean \"What is this?\" But without knowing the subject, it's still vague. Maybe the system needs to retrieve documents related to forming questions in French or common \"Qu'est-ce que...\" questions. \n",
      "\n",
      "Another angle: The user might be trying to use \"que est ce\" as a phrase, but in French, that's incorrect. The correct structure is \"Qu'est-ce que...\" So perhaps the refinement should correct the grammar and prompt for the subject. For example, \"Qu'est-ce que [subject] ? Veuillez pr√©ciser votre question.\" (What is [subject]? Please specify your question.)\n",
      "\n",
      "Considering document retrieval, if the query is too vague, the system might not find relevant documents. So the refinement should guide the user to provide more context or specify their question. The key is to correct the grammar and structure the query properly in French to aid in better search results. \n",
      "\n",
      "In summary, the refined query should correct \"que est ce\" to \"Qu'est-ce que...\" and prompt the user to specify the subject they're asking about. This way, the retrieval system can find documents related to the specific topic the user is interested in.\n",
      "</think>\n",
      "\n",
      "**Refined Query:**  \n",
      "\"Qu'est-ce que [sujet] ? Veuillez pr√©ciser votre demande (ex: Qu'est-ce que la philosophie ? Qu'est-ce qu'un algorithme ?).\"  \n",
      "\n",
      "**Reasoning:**  \n",
      "1. La formulation originale (\"que est ce\") est grammaticalement incorrecte en fran√ßais. La forme standard est \"Qu'est-ce que...\" suivie d'un sujet.  \n",
      "2. Ajout d'une structure claire pour guider l'utilisateur √† sp√©cifier un sujet concret (ex: science, concept, objet).  \n",
      "3. Inclusion d'exemples pour clarifier l'intention de la requ√™te et am√©liorer la pertinence des r√©sultats de recherche.  \n",
      "\n",
      "Cette version corrig√©e permettra une r√©cup√©ration de documents plus pr√©cise en ciblant des explications sur un sujet d√©fini.\n",
      "\n",
      "ü§ñ Chatbot: <think>\n",
      "Okay, the user asked \"que est ce\" which I think is French for \"what is it.\" But looking at the retrieved documents, all the sources are from a French football magazine called Les Cahiers du football. Let me check the documents to see if they mention \"est-ce que\" in a way that explains its meaning.\n",
      "\n",
      "The first two documents talk about the use of \"est-ce que\" in a communiqu√© from OL (probably Olympique Lyonnais). They mention that interrogative markers like subject inversion and \"est-ce que\" are omitted, making the question look more like a statement, with only punctuation indicating it's a question. So \"est-ce que\" is part of forming questions in French, but here it's being left out to present something as a fact.\n",
      "\n",
      "The other documents don't seem relevant to the user's query. They discuss asking impertinent questions and forum guidelines, which aren't about the phrase itself. Since the first two documents explain the use of \"est-ce que\" in forming questions, I can explain that \"est-ce que\" is a phrase used to form questions in French, and in the analyzed text, its omission changes the sentence's tone. The answer should include the sources from those documents. No other relevant info, so the answer is based on those two.\n",
      "</think>\n",
      "\n",
      "The phrase \"est-ce que\" is a common interrogative expression in French used to form questions. In the analyzed documents, it is noted that the omission of \"est-ce que\" (along with subject-verb inversion) in a specific context shifts the tone of a sentence from a question to a statement. Only the punctuation (e.g., a question mark) retains the interrogative nature, presenting the idea as a factual assertion rather than an open question. This stylistic choice highlights how linguistic structures influence perceived certainty or debate.  \n",
      "\n",
      "Sources:  \n",
      "- [Analyse litt√©raire : le communiqu√© officiel de l'OL - Les Cahiers du football](https://www.cahiersdufootball.net/article/analyse-litteraire-le-communique-officiel-de-lol-4280)  \n",
      "- [Page 1 of the same article](https://www.cahiersdufootball.net/article/analyse-litteraire-le-communique-officiel-de-lol-4280?page=1)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\n",
    "from langchain_azure_ai.embeddings import AzureAIEmbeddingsModel\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.retrievers import BM25Retriever\n",
    "\n",
    "\n",
    "chat_model = AzureAIChatCompletionsModel(endpoint=API_ENDPOINT, credential=API_KEY, model_name=\"DeepSeek-R1\")\n",
    "embeddings = AzureAIEmbeddingsModel(endpoint=API_ENDPOINT, credential=API_KEY, model_name=\"text-embedding-3-small\")\n",
    "\n",
    "# ‚úÖ Load Dataset & Vectorstore\n",
    "df = pd.read_parquet(\"cahiers-du-foot.parquet\")\n",
    "vector_store = Milvus(\n",
    "    embeddings,\n",
    "    index_params={\"index_type\": \"FLAT\", \"metric_type\": \"COSINE\"},\n",
    "    connection_args={\"uri\": \"milvus-cahiers-du-foot.db\"}\n",
    ")\n",
    "\n",
    "def is_english(text):\n",
    "    \"\"\"Checks if the input query is in English using DeepSeek-R1.\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a language detection assistant. \"\n",
    "                              \"Return only 'YES' if the text is in English, otherwise return 'NO'.\"),\n",
    "        HumanMessage(content=text)\n",
    "    ]\n",
    "    \n",
    "    response = chat_model.invoke(messages).content.strip().upper()\n",
    "\n",
    "    # Ensure response is strictly \"YES\" or \"NO\"\n",
    "    if response not in [\"YES\", \"NO\"]:\n",
    "        return True  # Assume English if uncertain\n",
    "\n",
    "    return response == \"YES\"\n",
    "\n",
    "\n",
    "# ‚úÖ Contextual Query Generation\n",
    "def contextual_query_generation(query, conversation_history):\n",
    "    \"\"\"\n",
    "    Pre-retrieval: Generates a more precise query using conversation context.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an intelligent assistant. Given the user's query and conversation history, \"\n",
    "                              \"refine the query to be more specific for document retrieval.\"),\n",
    "        HumanMessage(content=f\"User Query: \\\"{query}\\\"\\nConversation History: \\\"{conversation_history}\\\"\")\n",
    "    ]\n",
    "    refined_query = chat_model.invoke(messages).content.strip()\n",
    "    print(f\"[DEBUG] Refined Query: {refined_query}\")\n",
    "    return refined_query\n",
    "\n",
    "# ‚úÖ Adaptive Retrieval\n",
    "def adaptive_retrieval(query):\n",
    "    \"\"\"\n",
    "    Adaptive retrieval: Selects different numbers of candidate documents based on query complexity.\n",
    "    Uses a vector database for initial retrieval.\n",
    "    \"\"\"\n",
    "    k = 8 if len(query.split()) >= 5 else 5  # More documents for longer queries\n",
    "    print(f\"[DEBUG] Adaptive retrieval using k = {k}\")\n",
    "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    docs = retriever.invoke(query)\n",
    "    print(f\"[DEBUG] Retrieved {len(docs)} candidate documents.\")\n",
    "    return docs\n",
    "    \n",
    "# ‚úÖ Function to Translate English Query to French\n",
    "def translate_english_to_french(english_text):\n",
    "    \"\"\"Translates an English query into French using Mistral-Nemo.\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"Translate the following English text into fluent French.\"),\n",
    "        HumanMessage(content=english_text)\n",
    "    ]\n",
    "    mistral_model = AzureAIChatCompletionsModel(endpoint=API_ENDPOINT, credential=API_KEY, model_name=\"Mistral-Nemo\")\n",
    "    return mistral_model.invoke(messages).content\n",
    "\n",
    "# ‚úÖ Function to Retrieve Documents in French\n",
    "def retrieve_documents(query, top_k=5):\n",
    "    \"\"\"Retrieves the top_k most relevant documents in French.\"\"\"\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": top_k})\n",
    "    return retriever.invoke(query)\n",
    "\n",
    "# ‚úÖ Function to Translate French Documents to English\n",
    "def translate_french_to_english(french_text):\n",
    "    \"\"\"Translates a French document into English using Mistral-Nemo.\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"Translate the following French text into fluent English.\"),\n",
    "        HumanMessage(content=french_text)\n",
    "    ]\n",
    "    mistral_model = AzureAIChatCompletionsModel(endpoint=API_ENDPOINT, credential=API_KEY, model_name=\"Mistral-Nemo\")\n",
    "    return mistral_model.invoke(messages).content\n",
    "\n",
    "# ‚úÖ Function to Ensure Answer is Based on Relevant Sources\n",
    "def is_relevant_response(query, answer):\n",
    "    \"\"\"Verifies if the answer is relevant to the query using GPT-4o.\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"Check if the provided answer is relevant to the user's query. \"\n",
    "                              \"Return 'YES' if relevant, otherwise return 'I don't know'.\"),\n",
    "        HumanMessage(content=f\"Query: {query}\\n\\nAnswer: {answer}\")\n",
    "    ]\n",
    "    response = chat_model.invoke(messages).content.strip()\n",
    "    return response\n",
    "\n",
    "# ‚úÖ Function to Format Retrieved Documents\n",
    "def format_documents_for_chat(docs):\n",
    "    \"\"\"Formats retrieved documents for LLM input.\"\"\"\n",
    "    formatted_text = \"Here are the relevant documents:\\n\\n\"\n",
    "    for doc in docs:\n",
    "        formatted_text += f\"Title: {doc['title']}\\n\"\n",
    "        formatted_text += f\"URL: {doc['url']}\\n\"\n",
    "        formatted_text += f\"Content: {doc['content'][:500]}...\\n\\n\"  # Limit length to avoid exceeding context limit\n",
    "    return formatted_text\n",
    "\n",
    "\n",
    "# ‚úÖ Updated Response Generation with Contextual Query & Adaptive Retrieval\n",
    "def generate_hybrid_response(query, conversation_history=\"\"):\n",
    "\n",
    "    # üö´ Reject non-English queries\n",
    "    if not is_english(query):\n",
    "        return \"Please provide your input in English.\"\n",
    "        \n",
    "    \"\"\"Processes an English query, retrieves translated documents, and generates a response with sources.\"\"\"\n",
    "\n",
    "    # üîç Generate refined query using conversation history\n",
    "    refined_query = contextual_query_generation(query, conversation_history)\n",
    "\n",
    "    # üìñ Retrieve relevant documents (already in French)\n",
    "    retrieved_docs = retrieve_documents(refined_query)\n",
    "\n",
    "    # ‚ùå If no relevant documents, return \"I don't know.\"\n",
    "    if not retrieved_docs:\n",
    "        return \"I don't know.\"\n",
    "\n",
    "    # üîÑ Translate retrieved French documents to English using Mistral\n",
    "    translated_docs = [\n",
    "        {\n",
    "            \"title\": doc.metadata[\"title\"],\n",
    "            \"url\": doc.metadata[\"url\"],\n",
    "            \"content\": translate_french_to_english(doc.page_content)\n",
    "        }\n",
    "        for doc in retrieved_docs\n",
    "    ]\n",
    "\n",
    "    # üìù Format documents for LLM input\n",
    "    formatted_docs = format_documents_for_chat(translated_docs)\n",
    "\n",
    "    # üß† Use DeepSeek-R1 for reasoning\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You must answer only in English. \"\n",
    "                              \"Only take English input, if any other language instantly reply please give English\"\n",
    "                              \"Use only the retrieved documents. \"\n",
    "                             \"remember chat history, and answer stuff relevant to that too\"\n",
    "                              \"Translate them into English if needed. \"\n",
    "                              \"If no relevant documents exist, reply with 'I don't know.' \"\n",
    "                              \"In this case give no sources\"\n",
    "                              \"Include sources in the response, unless answer is I don't know\"\n",
    "                              \"Always give the links unless I dont know!!\"),\n",
    "        HumanMessage(content=f\"User Query: {query}\\n\\nHere are the retrieved documents:\\n\\n{formatted_docs}\")\n",
    "    ]\n",
    "    \n",
    "    response = chat_model.invoke(messages).content\n",
    "\n",
    "   \n",
    "    return response \n",
    "\n",
    "\n",
    "# ‚úÖ Inline User Interface (Simple Console Chatbot)\n",
    "def chatbot_interface():\n",
    "    \"\"\"Runs an interactive chatbot session.\"\"\"\n",
    "    print(\"üí¨ Chatbot Ready! Type 'exit' to stop.\")\n",
    "    while True:\n",
    "        query = input(\"\\nüîπ You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "        response = generate_hybrid_response(query)\n",
    "        print(\"\\nü§ñ Chatbot:\", response)\n",
    "\n",
    "# üî• Start Chatbot\n",
    "chatbot_interface()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34fb93e-ac29-40de-8ec3-1f3caa85084d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ GPT-4o Chatbot Ready! Type 'exit' to stop.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\n",
    "from langchain_azure_ai.embeddings import AzureAIEmbeddingsModel\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "\n",
    "# ‚úÖ Initialize GPT-4o Model\n",
    "chat_model = AzureAIChatCompletionsModel(endpoint=API_ENDPOINT, credential=API_KEY, model_name=\"gpt-4o\")\n",
    "\n",
    "# ‚úÖ Initialize Embedding Model\n",
    "embedding_model = AzureAIEmbeddingsModel(endpoint=API_ENDPOINT, credential=API_KEY, model_name=\"text-embedding-3-small\")\n",
    "\n",
    "# ‚úÖ Load Dataset & Vectorstore\n",
    "df = pd.read_parquet(\"cahiers-du-foot.parquet\")\n",
    "vector_store = Milvus(\n",
    "    embeddings,\n",
    "    index_params={\"index_type\": \"FLAT\", \"metric_type\": \"COSINE\"},\n",
    "    connection_args={\"uri\": \"milvus-cahiers-du-foot.db\"}\n",
    ")\n",
    "\n",
    "# ‚úÖ Function to Retrieve Relevant Documents (in French)\n",
    "def retrieve_documents(query, top_k=5):\n",
    "    \"\"\"Retrieves the top_k most relevant documents in French.\"\"\"\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": top_k})\n",
    "    return retriever.invoke(query)\n",
    "\n",
    "# ‚úÖ Function to Generate a Response Using Only GPT-4o\n",
    "def generate_response_gpt4(query):\n",
    "    \"\"\"Uses GPT-4o for translation, retrieval, and response generation in one step.\"\"\"\n",
    "\n",
    "    # üìñ Retrieve relevant documents (French)\n",
    "    retrieved_docs = retrieve_documents(query)\n",
    "\n",
    "    # ‚ùå If no relevant documents, return \"I don't know.\"\n",
    "    if not retrieved_docs:\n",
    "        return \"I don't know.\"\n",
    "\n",
    "    # üìù Format documents for input\n",
    "    formatted_docs = \"\\n\\n\".join(\n",
    "        [f\"Title: {doc.metadata['title']}\\nURL: {doc.metadata['url']}\\nContent: {doc.page_content[:500]}...\" for doc in retrieved_docs]\n",
    "    )\n",
    "\n",
    "    # ü§ñ Use GPT-4o for full pipeline (Translation + Reasoning)\n",
    "    messages = [\n",
    "        SystemMessage(content=\"Only take a response in english, if not return please give input in English\"\n",
    "                              \"You must answer only in English. \"\n",
    "                              \n",
    "                              \"Use only the retrieved documents. \"\n",
    "                             \"remember chat history, and answer stuff relevant to that too\"\n",
    "                              \"Translate them into English if needed. \"\n",
    "                              \"If no relevant documents exist, reply with 'I don't know.' \"\n",
    "                              \"Always include sources in the response, unless answer is I don't know\"\n",
    "                              \"Always give the links unless I dont know!!\"),\n",
    "        HumanMessage(content=f\"User Query: {query}\\n\\nHere are the retrieved documents:\\n\\n{formatted_docs}\")\n",
    "    ]\n",
    "    \n",
    "    response = chat_model.invoke(messages).content\n",
    "\n",
    "    \n",
    "    return response\n",
    "\n",
    "# ‚úÖ Simple Chat Interface\n",
    "def chatbot_interface():\n",
    "    \"\"\"Runs an interactive chatbot session using GPT-4o.\"\"\"\n",
    "    print(\"üí¨ GPT-4o Chatbot Ready! Type 'exit' to stop.\")\n",
    "    while True:\n",
    "        query = input(\"\\nüîπ You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "        response = generate_response_gpt4(query)\n",
    "        print(\"\\nü§ñ Chatbot:\", response)\n",
    "\n",
    "# üî• Start Chatbot\n",
    "chatbot_interface()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43153251-765d-4e66-a7b0-09e1c7858606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
